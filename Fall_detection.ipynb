{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Libraries**"
      ],
      "metadata": {
        "id": "4yA3EpNPW9-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import load_img\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#for testing\n",
        "from IPython.display import Image\n",
        "\n",
        "# for reading rgb for each pixel\n",
        "#   seems to be different Images\n",
        "from PIL import Image\n",
        "\n",
        "import array as arr\n",
        "\n",
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CZ4B1hxfuXzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3bf1d6-cfa8-4014-eaa7-57811b981201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "**Get Training and Test Data for Random Forests**\n",
        "<br><br>\n",
        "\n",
        "This cell read in data from a csv containing the keypoints, bounding boxes, and label for each image. Labels describe the motion of the person in the image. In this case only the label and the keypoints are extracted. At the end, you see data being splitted into training and testing."
      ],
      "metadata": {
        "id": "wmttP5hfrtLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/test.csv')\n",
        "\n",
        "#Setup training and testing data\n",
        "dataset['label']=(dataset['label'].map({-1:2, 0:0, 1:1}))#Switch -1 to 2 for classifier\n",
        "\n",
        "x=dataset['keypoints'].apply(eval).apply(list).values.tolist()\n",
        "x=np.array([np.array(xi) for xi in x])\n",
        "y=dataset['label'].values\n",
        "y=np.array([np.array(xi) for xi in y])\n",
        "\n",
        "x_train=x\n",
        "y_train=y"
      ],
      "metadata": {
        "id": "kl8XUg2aoPKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/test2.csv')\n",
        "\n",
        "#Setup training and testing data\n",
        "dataset['label']=(dataset['label'].map({-1:2, 0:0, 1:1}))#Switch -1 to 2 for classifier\n",
        "\n",
        "x=dataset['keypoints'].apply(eval).apply(list).values.tolist()\n",
        "x=np.array([np.array(xi) for xi in x])\n",
        "y=dataset['label'].values\n",
        "y=np.array([np.array(xi) for xi in y])\n",
        "\n",
        "\n",
        "x_test=x\n",
        "y_test=y"
      ],
      "metadata": {
        "id": "b3D1hTiVdL3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "**Train Random Forest Model**\n",
        "<br><br>\n",
        "\n",
        "The cell below is the Random Forest, which fit the random forest model to the training data, so it could be trained.\n",
        "\n",
        "The model is evaluated through testing it with the testing data, which in this case is x_test, the keypoint data.\n",
        "\n",
        "The evaluation is done with the classification report function."
      ],
      "metadata": {
        "id": "sudsh7gpsK-v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xliC77akoIi_",
        "outputId": "5f26fcdc-9871-41e9-ef25-c7152f22efce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.79      0.83        28\n",
            "           1       1.00      1.00      1.00        41\n",
            "           2       0.86      0.92      0.89        39\n",
            "\n",
            "    accuracy                           0.92       108\n",
            "   macro avg       0.91      0.90      0.91       108\n",
            "weighted avg       0.92      0.92      0.92       108\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "from ast import literal_eval\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Train and Test\n",
        "clf.fit(list(x_train), y_train)\n",
        "y_pred=clf.predict(list(x_test))\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "y_pred_RF=y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "**Get Dataset for CNN**"
      ],
      "metadata": {
        "id": "qF1ZIHSqf7b8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required module\n",
        "import os\n",
        " \n",
        "# assign directory\n",
        "directory = '/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-01-cam0-rgb'\n",
        "\n",
        "files=[]\n",
        "\n",
        "# iterate over files in\n",
        "# that directory\n",
        "for filename in os.scandir(directory):\n",
        "    if filename.is_file():\n",
        "        \n",
        "        files.append(filename.path)\n",
        "files.sort()\n",
        "(len(files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxIFVdjEunY7",
        "outputId": "92c63aa3-902d-4bcc-f989-c0817b10b418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "**(Function) Extract RGB Values**"
      ],
      "metadata": {
        "id": "YRORucWjYM4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_extract(file):\n",
        "  path = file\n",
        "\n",
        "\n",
        "  im = Image.open(path)\n",
        "  pix = im.load()               # pixel access object that can be manipulated\n",
        "\n",
        " \n",
        "  im_size = [im.width, im.height]\n",
        "\n",
        "\n",
        "  print(\"actual rgb at (639, 479) = {0}\".format(pix[639,479]))               # print RGBA value of image\n",
        "\n",
        "\n",
        "  # create 2D empty array [[y]x]\n",
        "  rgb_vals = [[0] * im.height] * im.width\n",
        "\n",
        "  for a in range(0, im.width):\n",
        "    for b in range(0, im.height):\n",
        "   \n",
        "      \n",
        "      rgb_vals[a][b] = pix[a,b]\n",
        "     \n",
        "  return np.array(rgb_vals)"
      ],
      "metadata": {
        "id": "fBC1MOznuSPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "**Extract rgb data from training set**"
      ],
      "metadata": {
        "id": "MJhizlAFgBGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract rgb files from each images\n",
        "import numpy as np \n",
        "a = []\n",
        "for file in files:\n",
        "  a.append(rgb_extract(file))\n",
        "a = np.asarray(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-cO9a-iusVh",
        "outputId": "7ba731a7-acbb-4958-9477-66d8a3598c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual rgb at (639, 479) = (69, 85, 84)\n",
            "actual rgb at (639, 479) = (62, 87, 84)\n",
            "actual rgb at (639, 479) = (60, 84, 86)\n",
            "actual rgb at (639, 479) = (70, 86, 86)\n",
            "actual rgb at (639, 479) = (72, 86, 95)\n",
            "actual rgb at (639, 479) = (69, 83, 92)\n",
            "actual rgb at (639, 479) = (69, 88, 82)\n",
            "actual rgb at (639, 479) = (71, 86, 91)\n",
            "actual rgb at (639, 479) = (70, 83, 89)\n",
            "actual rgb at (639, 479) = (71, 87, 87)\n",
            "actual rgb at (639, 479) = (71, 86, 93)\n",
            "actual rgb at (639, 479) = (71, 87, 86)\n",
            "actual rgb at (639, 479) = (70, 84, 85)\n",
            "actual rgb at (639, 479) = (69, 82, 88)\n",
            "actual rgb at (639, 479) = (72, 87, 90)\n",
            "actual rgb at (639, 479) = (71, 82, 84)\n",
            "actual rgb at (639, 479) = (72, 83, 87)\n",
            "actual rgb at (639, 479) = (74, 86, 86)\n",
            "actual rgb at (639, 479) = (70, 84, 87)\n",
            "actual rgb at (639, 479) = (68, 84, 84)\n",
            "actual rgb at (639, 479) = (72, 88, 85)\n",
            "actual rgb at (639, 479) = (70, 86, 86)\n",
            "actual rgb at (639, 479) = (67, 85, 89)\n",
            "actual rgb at (639, 479) = (65, 86, 87)\n",
            "actual rgb at (639, 479) = (72, 83, 85)\n",
            "actual rgb at (639, 479) = (69, 88, 84)\n",
            "actual rgb at (639, 479) = (70, 85, 82)\n",
            "actual rgb at (639, 479) = (69, 84, 87)\n",
            "actual rgb at (639, 479) = (69, 85, 85)\n",
            "actual rgb at (639, 479) = (69, 84, 89)\n",
            "actual rgb at (639, 479) = (69, 84, 89)\n",
            "actual rgb at (639, 479) = (70, 85, 90)\n",
            "actual rgb at (639, 479) = (74, 85, 89)\n",
            "actual rgb at (639, 479) = (72, 87, 92)\n",
            "actual rgb at (639, 479) = (69, 84, 89)\n",
            "actual rgb at (639, 479) = (73, 83, 92)\n",
            "actual rgb at (639, 479) = (70, 85, 92)\n",
            "actual rgb at (639, 479) = (71, 84, 90)\n",
            "actual rgb at (639, 479) = (68, 83, 88)\n",
            "actual rgb at (639, 479) = (69, 83, 84)\n",
            "actual rgb at (639, 479) = (71, 85, 88)\n",
            "actual rgb at (639, 479) = (71, 84, 90)\n",
            "actual rgb at (639, 479) = (70, 85, 88)\n",
            "actual rgb at (639, 479) = (71, 86, 91)\n",
            "actual rgb at (639, 479) = (71, 86, 91)\n",
            "actual rgb at (639, 479) = (72, 83, 85)\n",
            "actual rgb at (639, 479) = (69, 84, 87)\n",
            "actual rgb at (639, 479) = (67, 86, 80)\n",
            "actual rgb at (639, 479) = (72, 86, 89)\n",
            "actual rgb at (639, 479) = (71, 85, 94)\n",
            "actual rgb at (639, 479) = (71, 85, 86)\n",
            "actual rgb at (639, 479) = (69, 84, 87)\n",
            "actual rgb at (639, 479) = (68, 85, 92)\n",
            "actual rgb at (639, 479) = (67, 85, 87)\n",
            "actual rgb at (639, 479) = (69, 86, 94)\n",
            "actual rgb at (639, 479) = (71, 86, 89)\n",
            "actual rgb at (639, 479) = (70, 85, 88)\n",
            "actual rgb at (639, 479) = (66, 84, 88)\n",
            "actual rgb at (639, 479) = (69, 83, 92)\n",
            "actual rgb at (639, 479) = (68, 83, 86)\n",
            "actual rgb at (639, 479) = (72, 84, 82)\n",
            "actual rgb at (639, 479) = (70, 85, 88)\n",
            "actual rgb at (639, 479) = (72, 86, 89)\n",
            "actual rgb at (639, 479) = (66, 86, 95)\n",
            "actual rgb at (639, 479) = (70, 83, 89)\n",
            "actual rgb at (639, 479) = (68, 87, 93)\n",
            "actual rgb at (639, 479) = (69, 84, 91)\n",
            "actual rgb at (639, 479) = (69, 84, 91)\n",
            "actual rgb at (639, 479) = (68, 86, 100)\n",
            "actual rgb at (639, 479) = (72, 89, 97)\n",
            "actual rgb at (639, 479) = (70, 85, 92)\n",
            "actual rgb at (639, 479) = (70, 82, 96)\n",
            "actual rgb at (639, 479) = (69, 82, 90)\n",
            "actual rgb at (639, 479) = (67, 86, 90)\n",
            "actual rgb at (639, 479) = (69, 88, 92)\n",
            "actual rgb at (639, 479) = (70, 84, 87)\n",
            "actual rgb at (639, 479) = (70, 85, 88)\n",
            "actual rgb at (639, 479) = (72, 84, 84)\n",
            "actual rgb at (639, 479) = (70, 86, 86)\n",
            "actual rgb at (639, 479) = (70, 85, 90)\n",
            "actual rgb at (639, 479) = (68, 87, 91)\n",
            "actual rgb at (639, 479) = (72, 85, 91)\n",
            "actual rgb at (639, 479) = (72, 86, 95)\n",
            "actual rgb at (639, 479) = (74, 83, 90)\n",
            "actual rgb at (639, 479) = (69, 84, 89)\n",
            "actual rgb at (639, 479) = (69, 84, 89)\n",
            "actual rgb at (639, 479) = (71, 90, 88)\n",
            "actual rgb at (639, 479) = (70, 85, 88)\n",
            "actual rgb at (639, 479) = (71, 85, 94)\n",
            "actual rgb at (639, 479) = (72, 87, 94)\n",
            "actual rgb at (639, 479) = (71, 87, 87)\n",
            "actual rgb at (639, 479) = (72, 86, 89)\n",
            "actual rgb at (639, 479) = (70, 85, 88)\n",
            "actual rgb at (639, 479) = (71, 84, 90)\n",
            "actual rgb at (639, 479) = (71, 87, 84)\n",
            "actual rgb at (639, 479) = (69, 82, 88)\n",
            "actual rgb at (639, 479) = (69, 84, 89)\n",
            "actual rgb at (639, 479) = (69, 85, 82)\n",
            "actual rgb at (639, 479) = (71, 85, 85)\n",
            "actual rgb at (639, 479) = (69, 83, 86)\n",
            "actual rgb at (639, 479) = (73, 84, 90)\n",
            "actual rgb at (639, 479) = (71, 82, 86)\n",
            "actual rgb at (639, 479) = (71, 87, 87)\n",
            "actual rgb at (639, 479) = (71, 82, 84)\n",
            "actual rgb at (639, 479) = (69, 88, 95)\n",
            "actual rgb at (639, 479) = (67, 86, 90)\n",
            "actual rgb at (639, 479) = (69, 84, 87)\n",
            "actual rgb at (639, 479) = (73, 87, 90)\n",
            "actual rgb at (639, 479) = (71, 85, 88)\n",
            "actual rgb at (639, 479) = (69, 84, 87)\n",
            "actual rgb at (639, 479) = (73, 87, 88)\n",
            "actual rgb at (639, 479) = (68, 86, 90)\n",
            "actual rgb at (639, 479) = (71, 87, 87)\n",
            "actual rgb at (639, 479) = (74, 88, 88)\n",
            "actual rgb at (639, 479) = (61, 81, 92)\n",
            "actual rgb at (639, 479) = (74, 88, 89)\n",
            "actual rgb at (639, 479) = (70, 83, 92)\n",
            "actual rgb at (639, 479) = (70, 85, 90)\n",
            "actual rgb at (639, 479) = (69, 86, 93)\n",
            "actual rgb at (639, 479) = (70, 84, 87)\n",
            "actual rgb at (639, 479) = (73, 87, 90)\n",
            "actual rgb at (639, 479) = (72, 86, 89)\n",
            "actual rgb at (639, 479) = (71, 85, 94)\n",
            "actual rgb at (639, 479) = (71, 84, 90)\n",
            "actual rgb at (639, 479) = (72, 83, 87)\n",
            "actual rgb at (639, 479) = (71, 85, 85)\n",
            "actual rgb at (639, 479) = (73, 83, 92)\n",
            "actual rgb at (639, 479) = (71, 86, 91)\n",
            "actual rgb at (639, 479) = (72, 86, 89)\n",
            "actual rgb at (639, 479) = (75, 86, 90)\n",
            "actual rgb at (639, 479) = (70, 87, 95)\n",
            "actual rgb at (639, 479) = (74, 88, 91)\n",
            "actual rgb at (639, 479) = (71, 85, 88)\n",
            "actual rgb at (639, 479) = (73, 84, 88)\n",
            "actual rgb at (639, 479) = (70, 85, 90)\n",
            "actual rgb at (639, 479) = (75, 85, 87)\n",
            "actual rgb at (639, 479) = (73, 87, 90)\n",
            "actual rgb at (639, 479) = (73, 83, 85)\n",
            "actual rgb at (639, 479) = (74, 88, 89)\n",
            "actual rgb at (639, 479) = (75, 86, 90)\n",
            "actual rgb at (639, 479) = (73, 88, 85)\n",
            "actual rgb at (639, 479) = (70, 85, 92)\n",
            "actual rgb at (639, 479) = (72, 85, 91)\n",
            "actual rgb at (639, 479) = (67, 85, 87)\n",
            "actual rgb at (639, 479) = (69, 86, 93)\n",
            "actual rgb at (639, 479) = (71, 85, 96)\n",
            "actual rgb at (639, 479) = (70, 85, 92)\n",
            "actual rgb at (639, 479) = (75, 86, 88)\n",
            "actual rgb at (639, 479) = (65, 84, 82)\n",
            "actual rgb at (639, 479) = (67, 85, 85)\n",
            "actual rgb at (639, 479) = (71, 87, 87)\n",
            "actual rgb at (639, 479) = (75, 84, 89)\n",
            "actual rgb at (639, 479) = (67, 78, 80)\n",
            "actual rgb at (639, 479) = (72, 83, 87)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "**Obtain labels and bounding box from dataset**"
      ],
      "metadata": {
        "id": "_jKso1YPgLhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gather data for CNN.  Use image and bounding boxes for 2d cnn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "'''\n",
        "Read data set, use 'test.csv' is you cannot mount from drive, otherwise use '/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/test.csv'\n",
        "\n",
        "'''\n",
        "file='/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/test.csv'#'/content/drive/MyDrive/fall-01-cam0-rgb/test.csv'#Use for when drive is mounted\n",
        "#file='test.csv'#use for uploaded files\n",
        "dataset=pd.read_csv(file)\n",
        "\n",
        "#Change the labels so there are not any negatives\n",
        "dataset['label']=(dataset['label'].map({-1:2, 0:0, 1:1}))#Change -1 to 2\n",
        "\n",
        "#Reformat data\n",
        "\n",
        "x=a #X is the image data\n",
        "box=dataset['box'].apply(eval).apply(list).values.tolist()#Bounding box data\n",
        "y=dataset['label'].values\n",
        "y=np.array([np.array(xi) for xi in y])#Y is the label data\n"
      ],
      "metadata": {
        "id": "aXIEh5v0uw_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "4fliQ8B0u8NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "indices=range(154)\n",
        "\n",
        "xtrain=x\n",
        "ytrain=y\n",
        "xboxtrain=box\n",
        "xboxtrain = np.asarray(xboxtrain)\n",
        "yboxtrain=y\n"
      ],
      "metadata": {
        "id": "5wlAI_Nru2XK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "CNN Model - Get Training Data"
      ],
      "metadata": {
        "id": "L21dMagThewY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get list of image files names\n",
        "# import required module\n",
        "import os\n",
        " \n",
        "# assign directory\n",
        "directory = '/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb'\n",
        "\n",
        "files=[]\n",
        "\n",
        "# iterate over files in\n",
        "# that directory\n",
        "for filename in os.scandir(directory):\n",
        "    if filename.is_file():\n",
        "        \n",
        "        files.append(filename.path)\n",
        "files.sort()\n",
        "(len(files))\n",
        "\n",
        "\n",
        "\n",
        "#Extract rgb files from each images\n",
        "import numpy as np \n",
        "a = []\n",
        "for file in files:\n",
        "  a.append(rgb_extract(file))\n",
        "a = np.asarray(a)\n",
        "\n",
        "\n",
        "\n",
        "#Gather data for CNN.  Use image and bounding boxes for 2d cnn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "file='/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/test2.csv'\n",
        "#file='test.csv'#use for uploaded files\n",
        "dataset=pd.read_csv(file)\n",
        "\n",
        "#Change the labels so there are not any negatives\n",
        "dataset['label']=(dataset['label'].map({-1:2, 0:0, 1:1}))#Change -1 to 2\n",
        "\n",
        "#Reformat data\n",
        "\n",
        "x=a #X is the image data\n",
        "box=dataset['box'].apply(eval).apply(list).values.tolist()#Bounding box data\n",
        "y=dataset['label'].values\n",
        "y=np.array([np.array(xi) for xi in y])#Y is the label data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMEc25c7hJWH",
        "outputId": "755c3955-85c1-486f-fb8f-3d30e41d1a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual rgb at (639, 479) = (76, 87, 89)\n",
            "actual rgb at (639, 479) = (75, 85, 86)\n",
            "actual rgb at (639, 479) = (70, 83, 89)\n",
            "actual rgb at (639, 479) = (74, 85, 89)\n",
            "actual rgb at (639, 479) = (75, 86, 88)\n",
            "actual rgb at (639, 479) = (67, 79, 75)\n",
            "actual rgb at (639, 479) = (77, 86, 85)\n",
            "actual rgb at (639, 479) = (73, 85, 83)\n",
            "actual rgb at (639, 479) = (77, 87, 89)\n",
            "actual rgb at (639, 479) = (74, 85, 91)\n",
            "actual rgb at (639, 479) = (74, 83, 88)\n",
            "actual rgb at (639, 479) = (63, 77, 80)\n",
            "actual rgb at (639, 479) = (72, 86, 86)\n",
            "actual rgb at (639, 479) = (75, 87, 87)\n",
            "actual rgb at (639, 479) = (75, 89, 92)\n",
            "actual rgb at (639, 479) = (70, 85, 88)\n",
            "actual rgb at (639, 479) = (76, 87, 89)\n",
            "actual rgb at (639, 479) = (75, 86, 88)\n",
            "actual rgb at (639, 479) = (72, 87, 92)\n",
            "actual rgb at (639, 479) = (74, 87, 96)\n",
            "actual rgb at (639, 479) = (77, 87, 86)\n",
            "actual rgb at (639, 479) = (75, 86, 90)\n",
            "actual rgb at (639, 479) = (63, 81, 81)\n",
            "actual rgb at (639, 479) = (65, 76, 78)\n",
            "actual rgb at (639, 479) = (75, 86, 92)\n",
            "actual rgb at (639, 479) = (74, 89, 84)\n",
            "actual rgb at (639, 479) = (77, 87, 86)\n",
            "actual rgb at (639, 479) = (67, 77, 79)\n",
            "actual rgb at (639, 479) = (72, 90, 92)\n",
            "actual rgb at (639, 479) = (73, 87, 88)\n",
            "actual rgb at (639, 479) = (77, 87, 88)\n",
            "actual rgb at (639, 479) = (74, 86, 86)\n",
            "actual rgb at (639, 479) = (73, 89, 89)\n",
            "actual rgb at (639, 479) = (69, 87, 89)\n",
            "actual rgb at (639, 479) = (60, 75, 78)\n",
            "actual rgb at (639, 479) = (76, 83, 91)\n",
            "actual rgb at (639, 479) = (72, 87, 84)\n",
            "actual rgb at (639, 479) = (74, 84, 83)\n",
            "actual rgb at (639, 479) = (72, 87, 90)\n",
            "actual rgb at (639, 479) = (76, 88, 84)\n",
            "actual rgb at (639, 479) = (73, 87, 87)\n",
            "actual rgb at (639, 479) = (67, 83, 80)\n",
            "actual rgb at (639, 479) = (73, 88, 95)\n",
            "actual rgb at (639, 479) = (73, 86, 94)\n",
            "actual rgb at (639, 479) = (73, 87, 90)\n",
            "actual rgb at (639, 479) = (75, 84, 101)\n",
            "actual rgb at (639, 479) = (77, 87, 86)\n",
            "actual rgb at (639, 479) = (74, 84, 96)\n",
            "actual rgb at (639, 479) = (74, 85, 89)\n",
            "actual rgb at (639, 479) = (68, 86, 90)\n",
            "actual rgb at (639, 479) = (75, 85, 94)\n",
            "actual rgb at (639, 479) = (73, 87, 87)\n",
            "actual rgb at (639, 479) = (75, 86, 92)\n",
            "actual rgb at (639, 479) = (68, 85, 92)\n",
            "actual rgb at (639, 479) = (74, 85, 89)\n",
            "actual rgb at (639, 479) = (67, 83, 82)\n",
            "actual rgb at (639, 479) = (71, 85, 85)\n",
            "actual rgb at (639, 479) = (69, 84, 87)\n",
            "actual rgb at (639, 479) = (69, 84, 89)\n",
            "actual rgb at (639, 479) = (68, 83, 90)\n",
            "actual rgb at (639, 479) = (70, 84, 85)\n",
            "actual rgb at (639, 479) = (71, 85, 88)\n",
            "actual rgb at (639, 479) = (74, 85, 87)\n",
            "actual rgb at (639, 479) = (72, 85, 91)\n",
            "actual rgb at (639, 479) = (72, 86, 89)\n",
            "actual rgb at (639, 479) = (71, 85, 85)\n",
            "actual rgb at (639, 479) = (73, 83, 93)\n",
            "actual rgb at (639, 479) = (70, 85, 88)\n",
            "actual rgb at (639, 479) = (70, 87, 95)\n",
            "actual rgb at (639, 479) = (70, 84, 97)\n",
            "actual rgb at (639, 479) = (73, 87, 88)\n",
            "actual rgb at (639, 479) = (75, 86, 92)\n",
            "actual rgb at (639, 479) = (70, 83, 89)\n",
            "actual rgb at (639, 479) = (73, 84, 88)\n",
            "actual rgb at (639, 479) = (71, 84, 92)\n",
            "actual rgb at (639, 479) = (73, 89, 89)\n",
            "actual rgb at (639, 479) = (70, 85, 90)\n",
            "actual rgb at (639, 479) = (74, 88, 89)\n",
            "actual rgb at (639, 479) = (71, 84, 90)\n",
            "actual rgb at (639, 479) = (71, 85, 85)\n",
            "actual rgb at (639, 479) = (69, 84, 89)\n",
            "actual rgb at (639, 479) = (71, 84, 90)\n",
            "actual rgb at (639, 479) = (71, 84, 90)\n",
            "actual rgb at (639, 479) = (73, 84, 90)\n",
            "actual rgb at (639, 479) = (73, 89, 89)\n",
            "actual rgb at (639, 479) = (71, 85, 86)\n",
            "actual rgb at (639, 479) = (70, 84, 84)\n",
            "actual rgb at (639, 479) = (71, 86, 91)\n",
            "actual rgb at (639, 479) = (67, 82, 87)\n",
            "actual rgb at (639, 479) = (74, 84, 93)\n",
            "actual rgb at (639, 479) = (70, 85, 90)\n",
            "actual rgb at (639, 479) = (72, 83, 87)\n",
            "actual rgb at (639, 479) = (72, 83, 89)\n",
            "actual rgb at (639, 479) = (69, 84, 87)\n",
            "actual rgb at (639, 479) = (69, 84, 87)\n",
            "actual rgb at (639, 479) = (74, 85, 87)\n",
            "actual rgb at (639, 479) = (73, 82, 87)\n",
            "actual rgb at (639, 479) = (72, 87, 90)\n",
            "actual rgb at (639, 479) = (72, 84, 96)\n",
            "actual rgb at (639, 479) = (73, 84, 90)\n",
            "actual rgb at (639, 479) = (64, 83, 90)\n",
            "actual rgb at (639, 479) = (73, 84, 88)\n",
            "actual rgb at (639, 479) = (70, 84, 85)\n",
            "actual rgb at (639, 479) = (76, 86, 87)\n",
            "actual rgb at (639, 479) = (70, 85, 90)\n",
            "actual rgb at (639, 479) = (76, 86, 85)\n",
            "actual rgb at (639, 479) = (71, 86, 91)\n",
            "actual rgb at (639, 479) = (70, 83, 89)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtest=x\n",
        "ytest=y\n",
        "xboxtest=box\n",
        "xboxtest = np.asarray(xboxtest)\n",
        "yboxtest=y"
      ],
      "metadata": {
        "id": "7VGBDaD_rH-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "CNN Model - Set Up"
      ],
      "metadata": {
        "id": "Cnk6Qv9vYzjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Conv2D, Dense, Activation, Flatten, concatenate, Normalization,MaxPooling2D,Dropout,Rescaling\n",
        "from keras.models import Model\n",
        "\n",
        "image_input = Input(( 640, 480, 3))\n",
        "x=Rescaling(1./255),\n",
        "\n",
        "x = Conv2D(640, kernel_size=8, strides=4,activation='relu')(image_input)\n",
        "x=MaxPooling2D(pool_size=2, strides=2)(x)\n",
        "x=Dropout(0.25)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(3)(x)\n",
        "\n",
        "vector_input = Input((4,))\n",
        "\n",
        "y = Dense(3)(vector_input)\n",
        "\n",
        "z = concatenate([x, y])\n",
        "\n",
        "\n",
        "\n",
        "z = Dense(3)(z)\n",
        "z = Activation('softmax')(z)\n",
        "\n",
        "model = Model([image_input, vector_input], [z])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgcx1FrTu_f8",
        "outputId": "dc9730b2-9b78-4c74-de21-d3f7ef15d36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 640, 480, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 159, 119, 64  123520      ['input_1[0][0]']                \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 79, 59, 640)  0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 79, 59, 640)  0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2983040)      0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            8949123     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            15          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6)            0           ['dense[0][0]',                  \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 3)            21          ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 3)            0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,072,679\n",
            "Trainable params: 9,072,679\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),#cross entropy\n",
        "    optimizer=keras.optimizers.RMSprop(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "ZHM_qg6uvMR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the data\n",
        "v_min = xboxtrain.min(axis=(0, 1), keepdims=True)\n",
        "v_max = xboxtrain.max(axis=(0, 1), keepdims=True)\n",
        "xboxtrain=(xboxtrain - v_min)/(v_max - v_min)\n",
        "\n",
        "v_min = xtrain.min(axis=(0, 1), keepdims=True)\n",
        "v_max = xtrain.max(axis=(0, 1), keepdims=True)\n",
        "xtrain=(xtrain - v_min)/(v_max - v_min)\n",
        "\n",
        "v_min = xboxtest.min(axis=(0, 1), keepdims=True)\n",
        "v_max = xboxtest.max(axis=(0, 1), keepdims=True)\n",
        "xboxtest=(xboxtest - v_min)/(v_max - v_min)\n",
        "\n",
        "v_min = xtest.min(axis=(0, 1), keepdims=True)\n",
        "v_max = xtest.max(axis=(0, 1), keepdims=True)\n",
        "xtest=(xtest - v_min)/(v_max - v_min)"
      ],
      "metadata": {
        "id": "mDxo8jy6vSIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "CNN Model - Training"
      ],
      "metadata": {
        "id": "E3LuZJclnfCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=1\n",
        "\n",
        "history = model.fit(\n",
        "  [xtrain,xboxtrain],\n",
        "  ytrain,\n",
        "  validation_split=0.20,\n",
        "  epochs=epochs,\n",
        "  verbose=2,\n",
        "  shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf11oEwlvVfx",
        "outputId": "87a91fc6-74e4-49e0-eb5f-d2a24e41381d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 - 43s - loss: 89.3880 - accuracy: 0.5447 - val_loss: 13.0342 - val_accuracy: 0.0000e+00 - 43s/epoch - 11s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/Shareddrives/Team56_FallDetection/saved_models/my_model_9_demo_seventh_try')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqmmIdjxHm6f",
        "outputId": "6bb53fca-44f6-4f25-a0df-07009b7e1720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "CNN Model - Load Model"
      ],
      "metadata": {
        "id": "OAP5C7ADnj7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "new_model = tf.keras.models.load_model('/content/drive/Shareddrives/Team56_FallDetection/saved_models/my_model_9_demo_seventh_try')\n",
        "\n",
        "# Check its architecture\n",
        "new_model.summary()\n",
        "model=new_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UUdd38NIo3U",
        "outputId": "c16200b5-4018-4f79-ed18-1823aa8c9c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_37 (InputLayer)          [(None, 640, 480, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 159, 119, 64  123520      ['input_37[0][0]']               \n",
            "                                0)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_18 (MaxPooling2D  (None, 79, 59, 640)  0          ['conv2d_25[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 79, 59, 640)  0           ['max_pooling2d_18[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_16 (Flatten)           (None, 2983040)      0           ['dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            " input_38 (InputLayer)          [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_38 (Dense)               (None, 3)            8949123     ['flatten_16[0][0]']             \n",
            "                                                                                                  \n",
            " dense_39 (Dense)               (None, 3)            15          ['input_38[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 6)            0           ['dense_38[0][0]',               \n",
            "                                                                  'dense_39[0][0]']               \n",
            "                                                                                                  \n",
            " dense_40 (Dense)               (None, 3)            21          ['concatenate_13[0][0]']         \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 3)            0           ['dense_40[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,072,679\n",
            "Trainable params: 9,072,679\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ohe =model.predict([xtest, xboxtest])\n",
        "len(y_pred_ohe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yocS-1kvZ-m",
        "outputId": "972346a8-74a0-4891-a22a-7cd56b273bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 10s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred_labels = np.argmax(y_pred_ohe, axis=1)  \n",
        "\n",
        "print( confusion_matrix(y_true=ytest, y_pred=y_pred_labels))\n",
        "print(y_pred_labels)\n",
        "print(ytest)\n",
        "\n",
        "y_pred_CNN=y_pred_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DvbxntkvdZo",
        "outputId": "2ec11b73-e9e1-4d69-eaf4-61d3a85ac941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12  0 16]\n",
            " [ 4  0 37]\n",
            " [17  0 22]]\n",
            "[0 0 2 2 2 2 0 2 0 2 0 0 0 2 0 0 2 2 2 0 2 0 2 0 2 2 2 2 2 2 0 2 2 0 0 0 2\n",
            " 0 2 0 2 0 0 2 0 0 2 0 2 0 2 2 0 0 0 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2]\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(ytest, y_pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5wzN8Jcvgw9",
        "outputId": "7e2c455e-7068-40df-ae61-ca65548517f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.43      0.39        28\n",
            "           1       0.00      0.00      0.00        41\n",
            "           2       0.29      0.56      0.39        39\n",
            "\n",
            "    accuracy                           0.31       108\n",
            "   macro avg       0.22      0.33      0.26       108\n",
            "weighted avg       0.20      0.31      0.24       108\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# overlay text\n",
        "# Importing the PIL library\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "\n",
        "def text_to_image(image_path,label,new_image_path):\n",
        "# Open an Image\n",
        "  img = Image.open(image_path)\n",
        "\n",
        "\n",
        "  # Call draw Method to add 2D graphics in an image\n",
        "  I1 = ImageDraw.Draw(img)\n",
        "  \n",
        "  # Custom font style and font size\n",
        "  myFont = ImageFont.truetype('FreeMono.ttf', 65)\n",
        "  \n",
        "  # Add Text to an image\n",
        "  I1.text((10, 10), label, font=myFont, fill =(255, 0, 0))\n",
        "  \n",
        "  # Display edited image\n",
        "  img.show()\n",
        "  \n",
        "  # Save the edited image\n",
        "  img.save(new_image_path+image_path[(image_path.rindex(\"/\")+1):])"
      ],
      "metadata": {
        "id": "7thBN7On8XdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare results"
      ],
      "metadata": {
        "id": "hK67uwBlhuBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required module\n",
        "import os\n",
        " \n",
        "# assign directory\n",
        "directory = '/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb'#'/content/drive/MyDrive/fall-01-cam0-rgb/fall-01-cam0-rgb'\n",
        "\n",
        "files=[]\n",
        "\n",
        "# iterate over files in\n",
        "# that directory\n",
        "for filename in os.scandir(directory):\n",
        "    if filename.is_file():\n",
        "        \n",
        "        files.append(filename.path)\n",
        "files.sort()\n",
        "(len(files))\n",
        "\n",
        "\n",
        "print(y_pred_RF)\n",
        "print(y_pred_CNN)\n",
        "i=0\n",
        "while i<len(y_pred_RF):\n",
        "  if(y_pred_RF[i]==y_pred_CNN[i] and (y_pred_RF[i]==0)):\n",
        "    print(\"yes\")\n",
        "    print(files[i])\n",
        "    text_to_image(files[i],\"Fall\",\"/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb_labelled/\")\n",
        "  else:\n",
        "    text_to_image(files[i],\"\",\"/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb_labelled/\")\n",
        "    \n",
        "  i=i+1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA_yB99C89fv",
        "outputId": "7e1af142-7927-485c-ac53-a8074fb8d127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2\n",
            " 2 2 2 2 2 0 0 0 0 2 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 0 2 2 2 2 0 2 0 2 0 0 0 2 0 0 2 2 2 0 2 0 2 0 2 2 2 2 2 2 0 2 2 0 0 0 2\n",
            " 0 2 0 2 0 0 2 0 0 2 0 2 0 2 2 0 0 0 0 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 0 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2]\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-016.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-022.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-043.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-045.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-046.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-050.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-053.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-054.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-055.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-056.png\n",
            "yes\n",
            "/content/drive/Shareddrives/Team56_FallDetection/fall-01-cam0-rgb-20221014T162818Z-001/fall-01-cam0-rgb/fall-02-cam0-rgb/fall-02-cam0-rgb-060.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PgI6zo3s92qC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}